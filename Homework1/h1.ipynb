{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.io.arff import loadarff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "IMAGES_DIR = Path('images')\n",
    "DATA_DIR = Path('data')\n",
    "DATA_FILE = 'column_diagnosis.arff'\n",
    "DATA_PATH = DATA_DIR / DATA_FILE\n",
    "data = loadarff(DATA_PATH)\n",
    "df = pd.DataFrame(data[0])\n",
    "df['class'] = df['class'].str.decode('utf-8')\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "f_statistic, p_values = f_classif(X, y)\n",
    "\n",
    "f_statistic_df = pd.DataFrame({'feature': X.columns,\n",
    "                               'F': f_statistic,\n",
    "                               'p-value': p_values})\n",
    "f_statistic_df.sort_values('p-value')\n",
    "\n",
    "highest_discriminative_feature = f_statistic_df['feature'][f_statistic_df['F'].idxmax()]\n",
    "lowest_discriminative_feature = f_statistic_df['feature'][f_statistic_df['F'].idxmin()]\n",
    "\n",
    "print(f_statistic_df.sort_values('p-value'))\n",
    "print(\"\\n\")\n",
    "print(f\"Variable with the highest F-statistic and lowest p_value: {highest_discriminative_feature}\\n\")\n",
    "print(f\"Variable with the lowest F-statistic and highest p_value: {lowest_discriminative_feature}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Plot the class-conditional probability density functions for the two selected features\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for class_name in df['class'].unique():\n",
    "    sns.kdeplot(df[df['class'] == class_name][highest_discriminative_feature], label=class_name)\n",
    "\n",
    "plt.title(f\"Class Conditional Probability Density Function for {highest_discriminative_feature}\")\n",
    "plt.xlabel(highest_discriminative_feature)\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.savefig(IMAGES_DIR / 'prob_dens_highest_discriminative_feature.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for class_name in df['class'].unique():\n",
    "    sns.kdeplot(df[df['class'] == class_name][lowest_discriminative_feature], label=class_name)\n",
    "\n",
    "plt.title(f\"Class Conditional Probability Density Function for {lowest_discriminative_feature}\")\n",
    "plt.xlabel(lowest_discriminative_feature)\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.savefig(IMAGES_DIR /'prob_dens_lowest_discriminative_feature.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load and partition data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Define the range of depth limits and number of runs to average over\n",
    "depths = [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "runs = 10\n",
    "\n",
    "# Arrays to keep Acc Values\n",
    "train_acc = np.zeros((runs, len(depths))) # This is going to be a 10x8 array, because we want to keep all the accuracies for each run\n",
    "test_acc = np.zeros((runs, len(depths)))\n",
    "\n",
    "# Loop over the runs\n",
    "for j, depth in enumerate(depths): # Need enumerate since we need to index the depths to keep in arrays\n",
    "    for i in range(runs):\n",
    "        # Learn Classifier\n",
    "        predictor = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "        predictor.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on train and test set\n",
    "        y_predicted_train = predictor.predict(X_train)\n",
    "        y_predicted_test = predictor.predict(X_test)\n",
    "\n",
    "        # Compute accuracy\n",
    "        train_acc[i, j] = sk.metrics.accuracy_score(y_train, y_predicted_train)\n",
    "        test_acc[i, j] = sk.metrics.accuracy_score(y_test, y_predicted_test)\n",
    "\n",
    "# Compute mean and standard deviation for train and test accuracies\n",
    "train_acc_mean = np.mean(train_acc, axis=0)\n",
    "train_acc_std = np.std(train_acc, axis=0)\n",
    "test_acc_mean = np.mean(test_acc, axis=0)\n",
    "test_acc_std = np.std(test_acc, axis=0)\n",
    "\n",
    "# Plot Optional\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Accuracy vs. Depth Limit with 10 runs per depth limit')\n",
    "plt.errorbar(depths, train_acc_mean, yerr=train_acc_std, label='Train Accuracy')\n",
    "plt.errorbar(depths, test_acc_mean, yerr=test_acc_std, label='Test Accuracy')\n",
    "plt.xlabel('Depth Limit')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(IMAGES_DIR /'accuracy_vs_depth_limit.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the Exercise without Optional Part\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Accuracy vs. Depth Limit with 1 runs per depth limit')\n",
    "plt.plot(depths, train_acc[0], label='Train Accuracy') # Selecting the first run for each depth limit\n",
    "plt.plot(depths, test_acc[0], label='Test Accuracy')\n",
    "plt.xlabel('Depth Limit')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(IMAGES_DIR /'accuracy_vs_depth_limit_without_optional.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "<!-- As seen by both plots, the training accuracy increases as the depth limit of the decision tree increases. However, the testing accuracy increases until a certain depth limit (in this case around 4 or 5) and then starts to decrease. This is because the decision tree is overfitting the training data and is not generalizing well to the testing data.\n",
    "For the optional part, we can also see that the standard deviation is generally small for the training, indicating that the results are consistent across different random initializations of the data. However, the standard deviation is larger for the testing data, indicating that the testing data is more sensitive to the random initialization of the data. -->\n",
    "\n",
    "Como se vê em ambos os gráficos, a precisão de treino aumenta à medida que o limite de profundidade da árvore de decisão aumenta. No entanto, a precisão de teste aumenta até um certo limite de profundidade (neste caso, cerca de 4 ou 5) e depois começa a diminuir. Isto acontece porque a árvore de decisão está a dar overfit aos dados de treino e não está a aprender de modo a corretamente avaliar os dados de teste.\n",
    "No que toca à parte opcional, também podemos ver que o desvio padrão geralmente é pequeno no caso do treino, o que indica que os resultados são consistentes em diferentes inicializações aleatórias dos dados. No entanto, o desvio padrão é maior para os dados de teste, o que indica que os dados de teste são mais sensíveis à inicialização aleatória dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Learn a decision tree with a minimum number of samples per leaf = 20\n",
    "predictor = tree.DecisionTreeClassifier(min_samples_leaf=20,\n",
    "                                        random_state=0)\n",
    "\n",
    "# Fit all the data\n",
    "predictor.fit(X, y)\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "tree.plot_tree(predictor,\n",
    "                feature_names=X.columns,\n",
    "                filled=True,\n",
    "                class_names=predictor.classes_)\n",
    "plt.title('Decision Tree with Minimum Samples per Leaf = 20', fontsize=20)\n",
    "plt.savefig(IMAGES_DIR / 'decision_tree_min_samples_leaf_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com a árvore de decisão construída na alínea anterior, existem dois casos nos quais o indivíduo em questão tem um outcome de diagnóstico com Hérnia. Em primeiro lugar temos degree_spondy|olisthesis $\\leq 16.079$ e sacral_slope $\\leq 28.136$. \n",
    "Em segundo lugar, temos degree_spondy|olisthesis $\\leq 16.079$, sacral_slope $> 28.136$, pelvic_radius $ \\leq 117.36$ e sacral_slope $\\leq 40.149$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
